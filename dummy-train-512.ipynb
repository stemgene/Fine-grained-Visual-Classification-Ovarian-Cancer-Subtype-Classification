{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbf5d940",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-21T02:19:09.747791Z",
     "iopub.status.busy": "2023-11-21T02:19:09.747377Z",
     "iopub.status.idle": "2023-11-21T02:19:17.494116Z",
     "shell.execute_reply": "2023-11-21T02:19:17.493235Z"
    },
    "papermill": {
     "duration": 7.756521,
     "end_time": "2023-11-21T02:19:17.496633",
     "exception": false,
     "start_time": "2023-11-21T02:19:09.740112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import math\n",
    "import pdb\n",
    "import cv2\n",
    "import time\n",
    "import glob\n",
    "import timm\n",
    "import random\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "import torch.nn.functional as F\n",
    "import albumentations as A\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold,StratifiedGroupKFold, KFold\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99cfafae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T02:19:17.510778Z",
     "iopub.status.busy": "2023-11-21T02:19:17.509888Z",
     "iopub.status.idle": "2023-11-21T02:19:17.515681Z",
     "shell.execute_reply": "2023-11-21T02:19:17.514796Z"
    },
    "papermill": {
     "duration": 0.014533,
     "end_time": "2023-11-21T02:19:17.517956",
     "exception": false,
     "start_time": "2023-11-21T02:19:17.503423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666\n"
     ]
    }
   ],
   "source": [
    "# 计算batch size的方法\n",
    "# 1. 首先计算每张图片的size(MB) = L * W * Channel * float / 8 (bit -> Byte)\n",
    "image_size = 512 * 512 * 3 * 32 / 8  # Byte\n",
    "image_size = image_size / (1024 * 1024) # Byte -> MB\n",
    "# 2. batch size的大小建议为GPU显存的1/4到1/2，最高不能超过1/2，因为training时需要同时计算正向梯度图和反向传播的梯度。假设GPU的显存为8G，用1/4作为training，那么就是2G用来存放一个batch。\n",
    "batch_size_train = math.floor(2000 / image_size)\n",
    "print(batch_size_train)\n",
    "# 3. validation阶段的batch size = batch_size_train * 2 原因是validation阶段不需要做反向传播，所以batch size\n",
    "batch_size_val = batch_size_train * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af73e49b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T02:19:17.529985Z",
     "iopub.status.busy": "2023-11-21T02:19:17.529668Z",
     "iopub.status.idle": "2023-11-21T02:19:17.535875Z",
     "shell.execute_reply": "2023-11-21T02:19:17.535047Z"
    },
    "papermill": {
     "duration": 0.014354,
     "end_time": "2023-11-21T02:19:17.537806",
     "exception": false,
     "start_time": "2023-11-21T02:19:17.523452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed) # python\n",
    "    np.random.seed(seed) # numpy\n",
    "    torch.manual_seed(seed) # pytorch\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True # 当使用CuDNN（CUDA的深度神经网络库）时，通过将此设置为True，确保了卷积操作的输出在每次运行时是确定性的。\n",
    "    torch.backends.cudnn.benchmark = False # 关闭CuDNN的自动调整功能，以确保卷积等操作的计算时间在每次运行时相同。\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    # 设置PyTorch使用确定性算法。在深度学习中，有时候我们希望训练过程是确定性的，即相同的输入和参数会产生相同的输出。这有助于实现实验的可重复性\n",
    "    # 启用此选项会使用确定性的（但通常比非确定性的算法慢）算法，以确保相同的输入和参数在不同运行中产生相同的结果。\n",
    "    torch.use_deterministic_algorithms(True) \n",
    "    # 设置CUDA（GPU加速计算）库（cuBLAS）的工作空间配置。cuBLAS是NVIDIA提供的针对线性代数计算的GPU加速库。\n",
    "    # 该设置涉及到cuBLAS的内存配置，这个设置的目的是优化GPU上的cuBLAS操作，以提高性能。在一些情况下，手动调整这些配置可以对模型的训练速度产生影响。具体而言：\n",
    "    # :4096 这表示设置cuBLAS的默认工作空间大小为4 MB。这个值可能需要根据你的任务和硬件进行调整。\n",
    "    # 8 这是一个控制器限制的值，它与cuBLAS的性能有关。这个值也可能需要根据你的硬件和任务进行调整。\n",
    "    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38ba9b3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T02:19:17.549763Z",
     "iopub.status.busy": "2023-11-21T02:19:17.549193Z",
     "iopub.status.idle": "2023-11-21T02:19:17.617509Z",
     "shell.execute_reply": "2023-11-21T02:19:17.616607Z"
    },
    "papermill": {
     "duration": 0.076309,
     "end_time": "2023-11-21T02:19:17.619430",
     "exception": false,
     "start_time": "2023-11-21T02:19:17.543121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # step 1: hyperparameter\n",
    "    seed = 42\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # step 2: data\n",
    "    n_fold = 4\n",
    "    img_size = [512, 512]\n",
    "    train_bs = 32\n",
    "    valid_bs = train_bs * 2\n",
    "    # step 3: model\n",
    "    backbone = 'efficientnet_b0'\n",
    "    num_classes = 5\n",
    "    label_def = {\"HGSC\":0, 'EC':1, 'CC':2, 'LGSC':3, 'MC':4}\n",
    "    label_def_re = {0:\"HGSC\", 1:\"EC\", 2:'CC', 3:\"LGSC\", 4:'MC'}\n",
    "    # step 4: optimizer\n",
    "    epoch = 10\n",
    "    lr = 1e-3\n",
    "    wd = 1e-5\n",
    "    lr_drop = 8\n",
    "    # step 5: infer\n",
    "    TTA = True\n",
    "    # step 6: files\n",
    "    ckpt_fold = 'ckpt-1120'\n",
    "    ckpt_name = \"efficientnetb0_img512512_bs32_fold4_epoch10_lr1e3\"  # for submit\n",
    "    train_path = \"/kaggle/input/ubc-ocean-512/train_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ed3362a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T02:19:17.631517Z",
     "iopub.status.busy": "2023-11-21T02:19:17.631234Z",
     "iopub.status.idle": "2023-11-21T02:19:17.637957Z",
     "shell.execute_reply": "2023-11-21T02:19:17.637145Z"
    },
    "papermill": {
     "duration": 0.014814,
     "end_time": "2023-11-21T02:19:17.639816",
     "exception": false,
     "start_time": "2023-11-21T02:19:17.625002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_transforms(CFG):\n",
    "    data_transforms = {\n",
    "        \"train\": A.Compose([\n",
    "            # # dimension should be multiples of 32\n",
    "            # ref: https://github.com/facebookresearch/detr/blob/main/datasets/coco.py\n",
    "            A.Resize(*CFG.img_size, interpolation=cv2.INTER_NEAREST, p=1.0),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], p=1.0),  # ImageNet的pretrain经验参数\n",
    "            # A.HorizontalFlip(p=0.5),\n",
    "            # A.VerticalFlip(p=0.5),\n",
    "            # A.ShiftScaleRotate(shift_limit=0.625, scale_limit=0.05, rotate_limit=10, p=0.5),\n",
    "#             A.OneOf([\n",
    "#                 A.GridDistortion(num_steps=5, distort_limit=0.05, p=1.0), \n",
    "#                 A.OpticalDistortion(distort_limit=0.05, shift_limit=0.05, p=1.0),\n",
    "#                 A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=1.0)\n",
    "#             ], p=0.25),\n",
    "#             A.CoarseDropout(max_holes=8, max_height=CFG.img_size[0]//20, max_width=CFG.img_size[1]//20,\n",
    "#                            min_holes=5, fill_value=0, mask_fill_value=0, p=0.5),\n",
    "            \n",
    "        ]),\n",
    "        \"valid_test\": A.Compose([\n",
    "            A.Resize(*CFG.img_size, interpolation=cv2.INTER_NEAREST, p=1.0),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], p=1.0),\n",
    "        ])\n",
    "    }\n",
    "    return data_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef24f745",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T02:19:17.651539Z",
     "iopub.status.busy": "2023-11-21T02:19:17.651273Z",
     "iopub.status.idle": "2023-11-21T02:19:17.660336Z",
     "shell.execute_reply": "2023-11-21T02:19:17.659494Z"
    },
    "papermill": {
     "duration": 0.017011,
     "end_time": "2023-11-21T02:19:17.662184",
     "exception": false,
     "start_time": "2023-11-21T02:19:17.645173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class build_dataset(Dataset):\n",
    "    def __init__(self, df, train_val_flag=True, transforms=None):\n",
    "        self.df = df\n",
    "        self.train_val_flag = train_val_flag\n",
    "        self.img_paths = df['img_path'].tolist()\n",
    "        self.ids = df['image_id'].tolist()\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        if self.train_val_flag:\n",
    "            self.label = df['img_label'].tolist()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        id = self.ids[index]\n",
    "        img = Image.open(self.img_paths[index]).convert(\"RGB\")\n",
    "        \n",
    "        if self.train_val_flag: \n",
    "            data = self.transforms(image=np.array(img))\n",
    "            img = np.transpose(data['image'], (2, 0, 1))  # [c, h, w]\n",
    "            label = self.label[index]\n",
    "            return torch.tensor(img), torch.from_numpy(np.array(label).astype(int))  # 训练过程中包含ground truth\n",
    "        else: # test\n",
    "            ### augmentations\n",
    "            data = self.transforms(image=np.array(img))\n",
    "            img = np.transpose(data['image'], (2, 0, 1))\n",
    "            return torch.tensor(img), id # 测试过程中不能添加ground truth，但要保留id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20a6720a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T02:19:17.673943Z",
     "iopub.status.busy": "2023-11-21T02:19:17.673653Z",
     "iopub.status.idle": "2023-11-21T02:19:17.679704Z",
     "shell.execute_reply": "2023-11-21T02:19:17.679003Z"
    },
    "papermill": {
     "duration": 0.014117,
     "end_time": "2023-11-21T02:19:17.681631",
     "exception": false,
     "start_time": "2023-11-21T02:19:17.667514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_dataloader(df, fold, data_transforms):\n",
    "    train_df = df.query(\"fold!=@fold\").reset_index(drop=True)\n",
    "    valid_df = df.query(\"fold==@fold\").reset_index(drop=True)\n",
    "    train_dataset = build_dataset(train_df, train_val_flag=True, transforms=data_transforms['train'])\n",
    "    valid_dataset = build_dataset(valid_df, train_val_flag=True, transforms=data_transforms['valid_test'])\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=CFG.train_bs, num_workers=0, shuffle=True, pin_memory=True, drop_last=False)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=CFG.valid_bs, num_workers=0, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "430e5a4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T02:19:17.693231Z",
     "iopub.status.busy": "2023-11-21T02:19:17.692962Z",
     "iopub.status.idle": "2023-11-21T02:19:17.697671Z",
     "shell.execute_reply": "2023-11-21T02:19:17.696974Z"
    },
    "papermill": {
     "duration": 0.012596,
     "end_time": "2023-11-21T02:19:17.699544",
     "exception": false,
     "start_time": "2023-11-21T02:19:17.686948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(CFG, pretrain_flag=False):\n",
    "    if pretrain_flag:\n",
    "        pretrain_weights = \"imagenet\"\n",
    "    else:\n",
    "        pretrain_weights = False\n",
    "    model = timm.create_model(CFG.backbone,\n",
    "                             pretrained=pretrain_weights,\n",
    "                             num_classes=CFG.num_classes)\n",
    "    model.to(CFG.device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa47b883",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T02:19:17.711240Z",
     "iopub.status.busy": "2023-11-21T02:19:17.710971Z",
     "iopub.status.idle": "2023-11-21T02:19:17.714967Z",
     "shell.execute_reply": "2023-11-21T02:19:17.714230Z"
    },
    "papermill": {
     "duration": 0.011805,
     "end_time": "2023-11-21T02:19:17.716766",
     "exception": false,
     "start_time": "2023-11-21T02:19:17.704961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_loss():\n",
    "    CELoss = torch.nn.CrossEntropyLoss()\n",
    "    return {\"CELoss\": CELoss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6ec7c04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T02:19:17.728566Z",
     "iopub.status.busy": "2023-11-21T02:19:17.728327Z",
     "iopub.status.idle": "2023-11-21T02:19:17.736557Z",
     "shell.execute_reply": "2023-11-21T02:19:17.735857Z"
    },
    "papermill": {
     "duration": 0.01633,
     "end_time": "2023-11-21T02:19:17.738468",
     "exception": false,
     "start_time": "2023-11-21T02:19:17.722138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, optimizer, losses_dict, CFG):\n",
    "    model.train()\n",
    "    scaler = amp.GradScaler()   # 开启混合精度训练\n",
    "    losses_all, ce_all, total = 0, 0, 0\n",
    "    \n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=\"Train \")\n",
    "    for _, (images, gt) in pbar:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        images = images.to(CFG.device, dtype=torch.float) # [b, c, w, h]\n",
    "        gt = gt.to(CFG.device)\n",
    "        \n",
    "        with amp.autocast(enabled=True):\n",
    "            y_preds = model(images) #[b, c, w, h]\n",
    "            ce_loss = losses_dict[\"CELoss\"](y_preds, gt.long())\n",
    "            losses = ce_loss\n",
    "        \n",
    "        scaler.scale(losses).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        losses_all += losses.item()\n",
    "        ce_all += ce_loss.item()\n",
    "        total += gt.shape[0]\n",
    "    \n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(\"lr: {:.4f}\".format(current_lr), flush=True)\n",
    "    print(\"loss: {:.3f}, ce_all: {:.3f}\".format(losses_all/total, ce_all/total, flush=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb3ed66",
   "metadata": {
    "papermill": {
     "duration": 0.005076,
     "end_time": "2023-11-21T02:19:17.748899",
     "exception": false,
     "start_time": "2023-11-21T02:19:17.743823",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "补充知识：任何norm中如Batch Normalization中有两个可以学习的参数scale factor和shift factor\n",
    "\n",
    "https://blog.csdn.net/wildridder/article/details/88534844 中y_i中的gamma和beta这两个参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5263cce4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T02:19:17.760379Z",
     "iopub.status.busy": "2023-11-21T02:19:17.760126Z",
     "iopub.status.idle": "2023-11-21T02:19:17.772264Z",
     "shell.execute_reply": "2023-11-21T02:19:17.771416Z"
    },
    "papermill": {
     "duration": 0.020124,
     "end_time": "2023-11-21T02:19:17.774260",
     "exception": false,
     "start_time": "2023-11-21T02:19:17.754136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()  # 不要梯度图\n",
    "def valid_one_epoch(model, valid_loader, CFG):\n",
    "    model.eval()  # 计算出当前epoch中，把Norm中的scale/shift factor固定住\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(enumerate(valid_loader), total=len(valid_loader), desc=\"Valid \")\n",
    "    for _, (images, gt) in pbar:\n",
    "        images = images.to(CFG.device, dtype=torch.float) # [b, c, w, h]\n",
    "        gt = gt.to(CFG.device)\n",
    "        \n",
    "        y_preds = model(images)\n",
    "        _, y_preds = torch.max(y_preds.data, dim=1)\n",
    "        correct += (y_preds==gt).sum()\n",
    "        \n",
    "        total += gt.shape[0]\n",
    "    \n",
    "    val_acc = correct / total\n",
    "    print(\"val_acc: {:.2f}\".format(val_acc), flush=True)\n",
    "    \n",
    "    return val_acc\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_one_epoch(ckpt_paths, test_loader, CFG):\n",
    "    pred_ids = []\n",
    "    pred_cls = []\n",
    "    pbar = tqdm(enumerate(test_loader), total=len(test_loader), desc=\"Test: \")\n",
    "    for _, (images, ids) in pbar:\n",
    "        images = images.to(CFG.device, dtype=torch.float)  # [b, c, w, h]\n",
    "        model = build_model(CFG, pretrain_flag=False)\n",
    "        model.load_state_dict(torch.load(ckpt_paths))\n",
    "        model.eval()  # 固定 BN layer\n",
    "        \n",
    "        y_preds = model(images) # [bs, num_cls]  tensor([1.6443, -0.7230, -2.0762, 0.5059, -1.1870])\n",
    "        y_prob = F.softmax(y_preds, dim=1) # tensor([0.6679, 0.0626, 0.0162, 0.2139, 0.0394]) 和为1的\n",
    "        cls_pred = y_prob.argmax(1)  \n",
    "        \n",
    "        for pred in cls_pred.data.cpu().numpy():\n",
    "            pred_cls.append(pred)\n",
    "        for id in ids.data.cpu().numpy().tolist():\n",
    "            pred_ids.append(id) # 41 即41.png\n",
    "    return pred_ids, pred_cls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e8927e",
   "metadata": {
    "papermill": {
     "duration": 0.005118,
     "end_time": "2023-11-21T02:19:17.784813",
     "exception": false,
     "start_time": "2023-11-21T02:19:17.779695",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 训练过程 \n",
    "\n",
    "`train_val_flag = True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b6caef5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T02:19:17.796699Z",
     "iopub.status.busy": "2023-11-21T02:19:17.796450Z",
     "iopub.status.idle": "2023-11-21T02:19:17.815914Z",
     "shell.execute_reply": "2023-11-21T02:19:17.815233Z"
    },
    "papermill": {
     "duration": 0.027676,
     "end_time": "2023-11-21T02:19:17.817713",
     "exception": false,
     "start_time": "2023-11-21T02:19:17.790037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_seed(CFG.seed)\n",
    "ckpt_path = f\"/kaggle/working/{CFG.ckpt_fold}/{CFG.ckpt_name}\"\n",
    "if not os.path.exists(ckpt_path):\n",
    "    os.makedirs(ckpt_path)\n",
    "    \n",
    "train_val_flag = False\n",
    "if train_val_flag:\n",
    "    ############################################\n",
    "    ###### part 0: data preprocess & simple EDA\n",
    "    ############################################\n",
    "    # 样本筛选：这一段代码在以后的项目中并不会重复使用，仅仅是针对此项目其他图片很大，找一些小图片样本\n",
    "    df_ori = pd.read_csv(\"/kaggle/input/train-csv/train.csv\")\n",
    "    # df_ori = df_ori[df_ori['is_tma'] == True].reset_index()  # 只找一些尺寸比较小的图片\n",
    "    # print(df_ori)  # 25张 tma为true的图片，尺寸大约在3000*3000\n",
    "    \n",
    "    # Label mapping\n",
    "    encoder = LabelEncoder()\n",
    "    # method 1，在label那一列上原地修改\n",
    "    df_ori['label_str'] = df_ori['label']\n",
    "    df_ori['label'] = encoder.fit_transform(df_ori['label'])\n",
    "    # method 2, 新建一个img_label列\n",
    "    df_ori['img_label'] = encoder.transform(df_ori['label_str'])\n",
    "    # print(df_ori)\n",
    "    \n",
    "    # path mapping\n",
    "    FILES = sorted(glob(CFG.train_path + \"/*.png\")) # 查找匹配指定模式的文件路径名，返回list。\n",
    "    # print(FILES) # ['/kaggle/input/UBC-OCEAN/train_images/10077.png', '/kaggle/input/UBC-OCEAN/train_images/10143.png'...]\n",
    "    ID2FILE = {\n",
    "        int(os.path.basename(file).split(\".\")[0]) : file for file in FILES\n",
    "    }\n",
    "    # print(ID2FILE) # {10077: '/kaggle/input/UBC-OCEAN/train_images/10077.png', 10143: '/kaggle/input/UBC-OCEAN/train_images/10143.png',...}\n",
    "    def get_train_file_path(image_id):\n",
    "        return ID2FILE[image_id]\n",
    "    df_ori['img_path'] = df_ori['image_id'].apply(get_train_file_path)\n",
    "    # print(df_ori)\n",
    "    \n",
    "    ############################################################\n",
    "    ###### trick 1: cross validation train \n",
    "    ###### 分成几个fold分别推理融合，如果是fold==0，那就用0做training，1做valdation，如果是fold==1，那就用1做training，0做validation\n",
    "    ############################################################\n",
    "    # documents: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedGroupKFold.html\n",
    "    kf = KFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(df_ori)):\n",
    "        df_ori.loc[val_idx, 'fold'] = fold\n",
    "    # print(df_ori)      # 增加了一个fold列，里面有0和1（当前的k=2）\n",
    "    for fold in range(CFG.n_fold):\n",
    "        print(f\"#\"*40, flush=True)\n",
    "        print(f\"##### Fold: {fold}\", flush=True)\n",
    "        print(f\"#\"*40, flush=True)\n",
    "        print(\"Device: \", CFG.device)\n",
    "        \n",
    "        ############################################################\n",
    "        ###### step 2: combination \n",
    "        ###### build_transform & build_dataset() & build_dataloader()\n",
    "        ###### build_model() & build_loss()\n",
    "        ############################################################\n",
    "        data_transforms = build_transforms(CFG)\n",
    "        train_loader, valid_loader = build_dataloader(df_ori, fold, data_transforms)\n",
    "        model = build_model(CFG, pretrain_flag=False)\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.wd)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, CFG.lr_drop)\n",
    "        losses_dict = build_loss() # loss\n",
    "        \n",
    "        best_val_acc = 0\n",
    "        best_epoch = 0\n",
    "        \n",
    "        for epoch in range(1, CFG.epoch+1):\n",
    "            start_time = time.time()\n",
    "            ############################################################\n",
    "            ###### step 3: train & val \n",
    "            ############################################################\n",
    "            train_one_epoch(model, train_loader, optimizer, losses_dict, CFG)\n",
    "            lr_scheduler.step()\n",
    "            val_acc = valid_one_epoch(model, valid_loader, CFG)\n",
    "            # print(val_acc)\n",
    "            ############################################################\n",
    "            ###### step 4: Save best model\n",
    "            ############################################################\n",
    "            is_best = (val_acc > best_val_acc)\n",
    "            best_val_acc = max(val_acc, best_val_acc)\n",
    "            if is_best:\n",
    "                save_path = f\"{ckpt_path}/best_fold{fold}_epoch{epoch}.pth\"\n",
    "                if os.path.isfile(save_path):\n",
    "                    os.remove(save_path)\n",
    "                torch.save(model.state_dict(), save_path)\n",
    "            \n",
    "            epoch_time = time.time() - start_time\n",
    "            print(\"epoch: {}, time: {:.2f}s, best: {:.2f}\\n\".format(epoch, epoch_time, best_val_acc), flush=True)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251811fa",
   "metadata": {
    "papermill": {
     "duration": 0.005121,
     "end_time": "2023-11-21T02:19:17.828205",
     "exception": false,
     "start_time": "2023-11-21T02:19:17.823084",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 测试过程\n",
    "\n",
    "`test_flag = True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b1f64c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T02:19:17.839874Z",
     "iopub.status.busy": "2023-11-21T02:19:17.839614Z",
     "iopub.status.idle": "2023-11-21T02:19:25.940421Z",
     "shell.execute_reply": "2023-11-21T02:19:25.939402Z"
    },
    "papermill": {
     "duration": 8.108865,
     "end_time": "2023-11-21T02:19:25.942449",
     "exception": false,
     "start_time": "2023-11-21T02:19:17.833584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 1/1 [00:08<00:00,  8.04s/it]\n"
     ]
    }
   ],
   "source": [
    "test_flag = True\n",
    "if test_flag:\n",
    "    ############################################\n",
    "    ###### part 0: data preprocess & simple EDA\n",
    "    ############################################\n",
    "    ROOT_DIR = '/kaggle/input/'\n",
    "    TEST_DIR = '/kaggle/input/test-thumbnails'\n",
    "    ALT_TEST_DIR = '/kaggle/input/test_images'\n",
    "    # CKPT_DIR = f\"/kaggle/working/{CFG.ckpt_fold}/{CFG.ckpt_name}/best_fold1_epoch4.pth\" # 需要每次都更换\n",
    "    CKPT_DIR = \"/kaggle/input/ubc-temp/best_fold1_epoch4.pth\" # for kaggle submission\n",
    "    \n",
    "    def get_test_file_path(image_id):\n",
    "        if os.path.exists(f\"{TEST_DIR}/{image_id}_thumbnail.png\"):\n",
    "            return f\"{TEST_DIR}/{image_id}_thumbnail.png\"\n",
    "        else:\n",
    "            return f\"{ALT_TEST_DIR}/{image_id}.png\"\n",
    "    \n",
    "    df = pd.read_csv(f\"{ROOT_DIR}/ubc-test-csv/test.csv\")\n",
    "    df['img_path'] = df['image_id'].apply(get_test_file_path)\n",
    "    df['label'] = 0\n",
    "#     df_sub = pd.read_csv(f\"{ROOT_DIR}/sample_submission.csv\")\n",
    "    \n",
    "    ############################################\n",
    "    ###### part 1: data load & pred\n",
    "    ############################################\n",
    "    \n",
    "    data_transforms = build_transforms(CFG)\n",
    "    test_dataset = build_dataset(df, train_val_flag=False, transforms=data_transforms['valid_test'])\n",
    "    test_loader = DataLoader(test_dataset, batch_size=CFG.valid_bs, num_workers=0, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    pred_ids, pred_cls = test_one_epoch(CKPT_DIR, test_loader, CFG)\n",
    "    ############################################\n",
    "    ###### part 2: submit\n",
    "    ############################################\n",
    "    pred_df = pd.DataFrame({\n",
    "        \"image_id\": pred_ids,\n",
    "        \"label\": pred_cls,\n",
    "    })\n",
    "    def label_mapping(image_str):\n",
    "        return CFG.label_def_re[image_str]\n",
    "    pred_df['label'] = pred_df['label'].apply(label_mapping)\n",
    "    pred_df.to_csv('submission.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94f4aef",
   "metadata": {
    "papermill": {
     "duration": 0.005632,
     "end_time": "2023-11-21T02:19:25.953969",
     "exception": false,
     "start_time": "2023-11-21T02:19:25.948337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4013651,
     "sourceId": 6983721,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4013697,
     "sourceId": 6983789,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4032410,
     "sourceId": 7013342,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4032982,
     "sourceId": 7014460,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4033100,
     "sourceId": 7014681,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 21.356391,
   "end_time": "2023-11-21T02:19:27.781916",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-21T02:19:06.425525",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
